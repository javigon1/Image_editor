1.  jgonza20 and cli31
2.  TA from lab and OH
3.  UArray2b.c
    a2plain.c (build on the preliminary version provided)
    ppmtrans.c (starts from control flow until print to files/std)
        No required files not correctly implemented.
4. 
Data structures:
    UArray2b will be represented as a 2D array whose elements are blocks, and 
    each block is represented by a single Uarray. The index of elements in the
    Uarray will be coded so it corresponds to the index in UArray2b used for 
    clients.

Architectures and Worklog
i.  Set up files need to implement and make sure everything compiles correctly
    Code the implementation of uarray2b.h (refer to uarray2.c provided in hw2 
    solution)
    Encounter a difficulty: how to avoid using four nested for loop in block
    mapping function. Discussed of calling the mapping func of uarray2 and
    call the mapping func of uarray with a helper apply func. But failed
    because the type of parameter cannot fit. Still use a 4-ly nested for loop.
    Test each method in the interface with a self made test.c file contains main
    function to make sure it works
    Generally test with provided a2test.c until pass was successfully printed
    Run a2block.c to make sure the uarray2b struct can be successfully applied 
    on it.
ii. Code the implementation for a2plain.c (refer to a2block.c). Set default
    mapping to row major mapping because as discussed in part E it is faster
iii.figure out algorithms for 4 rotations:
    0 rotation: [col, row] unchanged
    90 rotation: [height - row - 1, col] avoid out of range
    180 rotation: [width - col - 1, height - row - 1]
    figure out how to deal with rotate animage that is not a square 
    -> create a new UArray2_T of pixels with new width and height to store the 
    rotated pixels. Assign it back to the original image after transformation 
    completed.
    For each major mapping (row/col/block), the apply func is the same because
    it is only responsible for the rotation of single pixel.
    Handle extra functions of flip and transpose (similarly)
ix. Now the control flow was settled. Go to IO part (actually can code io prior
    to control flow bc it is easier to test)
    Use Pnm_ppm Pnm_ppmread to read the given image into given struct
    Create a new UArray2_T (width and height depends on transformation) to take
    over the rotated pixels and assign it back.
    Update the width /height of given image
    Send to print IO
    Free the original pixel and the new pixel array2
x.  Timer part: define variables used for timing as in timing_test.c
    start timing right before the control flow of transformation; end timing
    right after it.
    Write a properly formatted print out to file function. We created a new
    struct to take over all the information we need to analyze.

Tests:
i.  djpeg commend line given in the spec. Use from-wind-cave image. Try 7
    transformations and run with valgrind. All passed.
ii. a single line/ array with extreme difference between width and height. Set
    default to block mapping. Try 7 trnasformations and run with valgrind. All
    passed.
iii.the mono.ppm file provided in /large folder. We are unable to open it either
    use extension in VSCode or use Xming. Fail to check

5. PART E
Picture to time: from-wind-cave
Info: width 2867 height 1603. Total pixels: 4595801

cpu MHz		: 2194.844
cache size	: 16896 KB
cache line size	: 64 B
model name	: Intel(R) Xeon(R) Silver 4214Y CPU @ 2.20GHz

Transformation      Mapping          Total time(ns)         Time per pixel
-rotation 0        row-major           229765536                 50
-rotation 90       row-major           394298361                 86
-rotation 180      row-major           231639753                 51
-rotation 270      row-major           388042639                 85
-transpose         row-major           382345451                 84
-flip horizontal   row-major           204717080                 45
-flip vertical     row-major           202153664                 44

-rotation 0        column-major        539808932                 118
-rotation 90       column-major        400997118                 88
-rotation 180      column-major        552386490                 121
-rotation 270      column-major        400242111                 87
-transpose         column-major        406502224                 89
-flip horizontal   column-major        513943950                 112      
-flip vertical     column-major        478656299                 105

-rotation 0        block-major         457731282                 100
-rotation 90       block-major         526230353                 115
-rotation 180      block-major         460117288                 101
-rotation 270      block-major         466608534                 102
-transpose         block-major         458736684                 100
-flip horizontal   block-major         459268966                 100
-flip vertical     block-major         443530304                 97

Observe the data table, we can find 4 patterns:
1. row-major has generally the best performance compared to column-major and
block-major;
2. In row-major mapping, rotation 90, 270, and transpose is significantly slower
than rotation 0, 180, and flip horizontal, vertical
3. In col-major mapping, it is the opposite to pattern 2 in row-major mapping.
4. All the transformation in block-major mapping have generally the same
performace

For pattern 1, the design submission already explained why row-major is the best
performace. Please refer to the design.pdf

To explain pattern 2, we must first understand what does each element 
(pixel) do in the array in individual apply function. For example, in rotation
0, in this line of code:
Pnm_rgb rotated_pixel = info->methods->at(info->array2, i, j);
CPU would call the element ptr and the ptr to its destination in the new array2.
When putting both the elem and destination into cache, the cache line would also
take the next 4 entries after them. (cache line size = 64 bytes, each pixel has
3*4 = 12 bytes, each cache line can take 5 complete pixels)
So when the mapping function keeps going, CPU would find the next 4 pixel and 
methods->at in cache, which means a cache hit. It will proceed to 4 more hits
until a new pixel to be read in cache line 
However, in rotation 90, the rotation code is:
Pnm_rgb rotated_pixel = info->methods->at(info->array2, height - j - 1, i);
int i would increment every time the apply func was called in row-major, so
while the pixel was read one after another the same way as rotate 0, the
destination would move column-wise, which means incontigously in memory. For
the first line, every time methods->at was called it is a miss, which would
result in worse performance.
In short, when the transformation involves move pixel to its destination 
column-wise,the performace would be worse because one of the two data retrive
would have more cache line miss. Therefore, rotation 90, 270, and transpose is 
significantly slower than rotation 0, 180, and flip horizontal, vertical

To explain pattern 3, it is because when reading pixels column-wise, it will
cause the original pixel reading column-wise (the same as how rotation 90 was
explained in pattern 2) and methods->at as well. Therefore technically it is
double the worse performace than the likes of rotation 90 in pattern 2. And when
it comes to rotation 90s, we can see that the methods->at was calling pixels
horizontally again (you may envision it as double rotate 90 to make a 180), so
it has one good performace operation and one bad.
Even data can be used to prove the pattern, two good performace operation use 
about 50 ns on each pixel, one good one bad use about 85 (50 + 35) ns, and 
two bad operation use about 120 (50 + 35 * 2) ns.

To explain pattern 4, we must understand that the mapping function iterate
through each block first, and block was represented as Uarray, which is always
contigous in memory. Therefore retrieving pixel vertically or horizontally will
not affect the performace. When we call by default like this test, the block
size was set large enough to take more than one cache line, which means every
block are incontigous in memory. It would end up a neither good nor bad
performace, as we see in data, the time took for each block-major operation is
better than the two worse operations but worse than the two bad operations.
